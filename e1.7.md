```
(define (sqrt-iter guess x)
  (if (good-enough? guess x)
      guess
      (sqrt-iter (improve guess x)
                 x)))

(define (improve guess x)
  (average guess (/ x guess)))

(define (average x y)
  (/ (+ x y) 2))

(define (good-enough? guess x)
  (< (abs (- (square guess) x)) 0.001))

(define (sqrt x)
  (sqrt-iter 1.0 x))
```


Exercise 1.7.  The good-enough? test used in computing square roots will not be very effective for finding the square roots of very small numbers. Also, in real computers, arithmetic operations are almost always performed with limited precision. This makes our test inadequate for very large numbers. Explain these statements, with examples showing how the test fails for small and large numbers. An alternative strategy for implementing good-enough? is to watch how guess changes from one iteration to the next and to stop when the change is a very small fraction of the guess. Design a square-root procedure that uses this kind of end test. Does this work better for small and large numbers?

`The good-enough? test used in computing square roots will not be very effective for finding the square roots of very small numbers.`
I expect this is due to the fact that our precision is limited to .001, so for tiny numbers we'd
stop as soon as x would be within .001 of the actual value, but this could still quite far off from the actual
square root in terms of significant digits / percentage of the searched for value.

`limited precision arithmetic makes our test inadequate for very large numbers.`
Similarly, for a really big number we'd never get within the .001 window, because we could exceed the float's
significant digits of accuracy, getting close but never becoming more-accurate after a time.